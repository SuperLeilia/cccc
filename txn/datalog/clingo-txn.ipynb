{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import linecache\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from clorm import *\n",
    "from clorm import monkey\n",
    "monkey.patch()  # must call this before importing clingo\n",
    "from clorm.clingo import *\n",
    "from clorm.clingo import Control\n",
    "\n",
    "class Operation:\n",
    "    def __init__(self, data_type, var, val, client_id, txn_id):\n",
    "        self.data_type = data_type\n",
    "        self.var = var\n",
    "        self.val = val\n",
    "        self.client_id = client_id\n",
    "        self.txn_id = txn_id\n",
    "\n",
    "class Wtxn(Predicate):\n",
    "    op_1 = StringField\n",
    "    op_2 = StringField\n",
    "\n",
    "class So(Predicate):\n",
    "    op_1 = StringField\n",
    "    op_2 = StringField\n",
    "\n",
    "class Wsv(Predicate):\n",
    "    op_1 = StringField\n",
    "    op_2 = StringField\n",
    "\n",
    "class Wr(Predicate):\n",
    "    op_1 = StringField\n",
    "    op_2 = StringField\n",
    "    op_3 = StringField\n",
    "    \n",
    "class Cc(Predicate):\n",
    "    op_1 = StringField\n",
    "    op_2 = StringField\n",
    "\n",
    "class Co(Predicate):\n",
    "    op_1 = StringField\n",
    "    op_2 = StringField\n",
    "    \n",
    "class Tcc(Predicate):\n",
    "    op_1 = StringField\n",
    "    op_2 = StringField\n",
    "    \n",
    "class Bad_CyclicSOWR(Predicate):\n",
    "    op_1 = StringField\n",
    "\n",
    "class Bad_CyclicCO(Predicate):\n",
    "    op_1 = StringField\n",
    "\n",
    "class Show(Predicate):\n",
    "    op_1 = StringField\n",
    "    op_2 = StringField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiGraph:\n",
    "    def __init__(self):\n",
    "        self.adj_map = {}\n",
    "\n",
    "    def add_edge(self, from_node, to_node):\n",
    "        if from_node in self.adj_map:\n",
    "            self.adj_map[from_node].add(to_node)\n",
    "        else:\n",
    "            self.adj_map[from_node] = {to_node}\n",
    "\n",
    "    def add_edges(self, from_node, to_nodes):\n",
    "        if from_node not in self.adj_map:\n",
    "            self.adj_map[from_node] = set()\n",
    "        for to_node in to_nodes:\n",
    "            self.adj_map[from_node].add(to_node)\n",
    "\n",
    "    def add_vertex(self, new_node):\n",
    "        if new_node not in self.adj_map:\n",
    "            self.adj_map[new_node] = set()\n",
    "\n",
    "    def has_edge(self, from_node, to_node):\n",
    "        if from_node in self.adj_map and to_node in self.adj_map[from_node]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "class ClingoTxnHistory:\n",
    "    def __init__(self, ops):\n",
    "        self.wr_rel = {}\n",
    "        self.txns = {}\n",
    "        client_in_so = {}\n",
    "        r_nodes = {}\n",
    "        current_tra = []\n",
    "        self.facts = []\n",
    "        for i in range(len(ops)):\n",
    "            op_dict = self.get_op(ops[i])\n",
    "            if i == len(ops) - 1 or self.get_op(ops[i + 1])['tra_id'] != op_dict['tra_id']:\n",
    "                if op_dict['client_id'] in client_in_so:\n",
    "                    self.facts.append('so(\"' +  str(client_in_so[op_dict['client_id']]) + '\",\"' + str(op_dict['tra_id']) + '\")\\n')\n",
    "                client_in_so[op_dict['client_id']] = op_dict['tra_id']\n",
    "                current_tra.append(op_dict)\n",
    "                for op in current_tra:\n",
    "                    if op['op_type'] == 'w':\n",
    "                        wtxn_str = 'wtxn(\"' + str(op_dict['tra_id']) + '\",\"' + str(op['var']) + '\")\\n'\n",
    "                        if wtxn_str not in self.facts:\n",
    "                            self.facts.append('wtxn(\"' + str(op_dict['tra_id']) + '\",\"' + str(op['var']) + '\")\\n')\n",
    "                        if op['var'] in self.wr_rel:\n",
    "                            for key in list(self.wr_rel[op['var']].adj_map):\n",
    "                                wsv_str_1 = 'wsv(\"' +  str(key) + '\",\"' + str(op_dict['tra_id']) + '\")\\n'\n",
    "                                wsv_str_2 = 'wsv(\"' +  str(op_dict['tra_id']) + '\",\"' + str(key) + '\")\\n'\n",
    "                                if wsv_str_1 not in self.facts and wsv_str_2 not in self.facts:\n",
    "                                    self.facts.append(wsv_str_1)\n",
    "                            self.wr_rel[op['var']].add_vertex(op_dict['tra_id'])\n",
    "                        else:\n",
    "                            graph = DiGraph()\n",
    "                            graph.add_vertex(op_dict['tra_id'])\n",
    "                            self.wr_rel[op['var']] = graph\n",
    "                        if op['var'] in r_nodes:\n",
    "                            for key in r_nodes[op['var']]:\n",
    "                                if key != op_dict['tra_id']:\n",
    "                                    for node in self.txns[key]:\n",
    "                                        if node['val'] == op['val'] and node['var'] == op['var'] and node[\n",
    "                                            'op_type'] == 'r':\n",
    "                                            wr_str = 'wr(\"' + str(op_dict['tra_id']) + '\",\"' + str(key) + '\",\"' + str(op['var']) + '\")\\n'\n",
    "                                            if wr_str not in self.facts:\n",
    "                                                self.facts.append(wr_str)\n",
    "                                            self.wr_rel[op['var']].add_edge(op_dict['tra_id'], key)\n",
    "                                            break\n",
    "                    else:\n",
    "                        if op['var'] in self.wr_rel:\n",
    "                            has_wr = False\n",
    "                            for key, t_set in self.wr_rel[op['var']].adj_map.items():\n",
    "                                if key != op_dict['tra_id']:\n",
    "                                    for node in self.txns[key]:\n",
    "                                        if node['val'] == op['val'] and node['var'] == op['var'] and node[\n",
    "                                            'op_type'] == 'w':\n",
    "                                            t_set.add(op_dict['tra_id'])\n",
    "                                            wr_str = 'wr(\"' + str(key) + '\",\"' + str(op_dict['tra_id']) + '\",\"' + str(op['var']) + '\")\\n'\n",
    "                                            if wr_str not in self.facts:\n",
    "                                                self.facts.append(wr_str)\n",
    "                                            has_wr = True\n",
    "                                            break\n",
    "                                    if has_wr:\n",
    "                                        break\n",
    "                        if op['var'] not in r_nodes:\n",
    "                            r_nodes[op['var']] = set()\n",
    "                        r_nodes[op['var']].add(op_dict['tra_id'])\n",
    "                if op_dict['tra_id'] not in self.txns:\n",
    "                    self.txns[op_dict['tra_id']] = []\n",
    "                self.txns[op_dict['tra_id']].extend(current_tra.copy())\n",
    "                current_tra.clear()\n",
    "            else:\n",
    "                current_tra.append(op_dict)\n",
    "                \n",
    "    def get_op(self, op):\n",
    "        op = op.strip('\\n')\n",
    "        arr = op[2:-1].split(',')\n",
    "        if arr[1] == '':\n",
    "            print('Error: empty!')\n",
    "        return {\n",
    "            'op_type': op[0],\n",
    "            'var': arr[0],\n",
    "            'val': arr[1],\n",
    "            'client_id': int(arr[2]),\n",
    "            'tra_id': int(arr[3]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_facts(data):\n",
    "    facts = FactBase()\n",
    "    readZero = False\n",
    "    for i in range (0,len(data)):\n",
    "        if data[i].startswith('so'):\n",
    "            temp = data[i].split('\"')\n",
    "            temp1 = temp[1]\n",
    "            temp2 = temp[3]\n",
    "            facts.add(So(temp1,temp2))\n",
    "        if data[i].startswith('wtxn'):\n",
    "            temp = data[i].split('\"')\n",
    "            temp1 = temp[1]\n",
    "            temp2 = temp[3]\n",
    "            facts.add(Wtxn(temp1,temp2))\n",
    "        if data[i].startswith('wr'):\n",
    "            temp = data[i].split('\"')\n",
    "            temp1 = temp[1]\n",
    "            temp2 = temp[3]\n",
    "            temp3 = temp[5]\n",
    "            facts.add(Wr(temp1,temp2,temp3))\n",
    "        if data[i].startswith('wsv'):\n",
    "            temp = data[i].split('\"')\n",
    "            temp1 = temp[1]\n",
    "            temp2 = temp[3]\n",
    "            facts.add(Wsv(temp1,temp2))\n",
    "    return facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(url):\n",
    "    ASP_PROGRAM = \"rules.lp\"\n",
    "    data = linecache.getlines(url)\n",
    "    facts_plain = ClingoTxnHistory(data)\n",
    "    \n",
    "    facts = store_facts(facts_plain.facts)\n",
    "    \n",
    "    ctrl = Control(unifier=[Bad_CyclicCO])\n",
    "    ctrl.load(ASP_PROGRAM)\n",
    "    ctrl.add_facts(facts)\n",
    "    ctrl.ground([(\"base\", [])])\n",
    "    solution = None\n",
    "    return_list = [0, 0]\n",
    "\n",
    "    def on_model(model):\n",
    "        solution = model.facts(atoms=True)\n",
    "        bad_1 = solution.select(Bad_CyclicCO).get()\n",
    "        if (len(bad_1)) > 0:\n",
    "            print('BP!!!')\n",
    "            return_list[0] = 1\n",
    "            return_list[1] = 1\n",
    "    ctrl.solve(on_model=on_model)\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start!\n",
      "../../2_bug//data_result_48.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_49.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_11.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_39.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_38.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_10.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_12.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_13.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_9.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_17.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_16.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_8.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_28.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_14.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_15.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_29.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_6.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_24.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_30.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_18.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_19.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_31.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_25.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_7.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_5.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_33.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_27.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_26.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_32.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_4.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_0.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_36.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_22.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_23.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_37.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_1.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_3.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_21.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_35.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_34.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_20.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_2.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_47.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_46.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_44.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_45.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_41.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_40.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_42.txt\n",
      "BP!!!\n",
      "../../2_bug//data_result_43.txt\n",
      "BP!!!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('Start!')\n",
    "    url = '../../2_bug/'\n",
    "#     files = (fn for fn in os.listdir(url) if fn.endswith('.txt'))\n",
    "    files = (fn for fn in os.listdir(url) if fn.endswith('.txt') and fn.startswith('data'))\n",
    "    if os.path.exists('result/result.csv'):\n",
    "        os.remove('result/result.csv')\n",
    "    df = pd.DataFrame(\n",
    "            [], [],\n",
    "            ['co', 'violation'])\n",
    "    for file in files:\n",
    "        file_url = url + '/' + str(file)\n",
    "        print(file_url)\n",
    "        detect_list = detection(file_url)\n",
    "        df.loc[file] = detect_list\n",
    "    df.to_csv('result/result.csv')\n",
    "\n",
    "#     for folder in folders:\n",
    "#         df = pd.DataFrame(\n",
    "#             [], [],\n",
    "#             ['bad_pattern1', 'bad_pattern2', 'violation'])\n",
    "#         files = (fn for fn in os.listdir(url + '/' + folder))\n",
    "#         for file in files:\n",
    "#             file_url = url + '/' + folder + '/' + file\n",
    "#             detect_list = detection(file_url)\n",
    "#             df.loc[file] = detect_list\n",
    "#         df.to_csv('result/' + folder + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST BLOCK\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     folder_name = '../data/example3.txt'\n",
    "#     df = pd.DataFrame([], [], ['bad_pattern1', 'bad_pattern2', 'violation'])\n",
    "#     detect_list, duration = detection(folder_name)\n",
    "#     df.loc['facts_2.txt'] = detect_list\n",
    "#     df.loc['Total'] = df.apply(lambda x: x.sum())\n",
    "#     df.to_csv('../data/results/version_2/Cockreach/123.csv')\n",
    "#     print(detect_list)\n",
    "#     print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
